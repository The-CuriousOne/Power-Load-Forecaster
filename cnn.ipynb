{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training, validation, and test data\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "X_val = pd.read_csv('X_val.csv')\n",
    "y_val = pd.read_csv('y_val.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values.flatten()\n",
    "X_val_np = X_val.values\n",
    "y_val_np = y_val.values.flatten()\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using PCA to reduce features\n",
    "n_components = 10 \n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_reduced = pca.fit_transform(X_train_np)\n",
    "X_val_reduced = pca.transform(X_val_np)\n",
    "X_test_reduced = pca.transform(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to fit CNN input format (batch_size, channels, height, width)\n",
    "X_train_reduced = X_train_reduced.reshape((X_train_reduced.shape[0], 1, 1, n_components))\n",
    "X_val_reduced = X_val_reduced.reshape((X_val_reduced.shape[0], 1, 1, n_components))\n",
    "X_test_reduced = X_test_reduced.reshape((X_test_reduced.shape[0], 1, 1, n_components))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(1, 3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(1, 3))\n",
    "        self.fc1 = nn.Linear(32 * 1 * (n_components - 4), 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = CNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors with float32 dtype\n",
    "X_train_tensor = torch.tensor(X_train_reduced, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_reduced, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_reduced, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch processing\n",
    "batch_size = 1000 \n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to log training loss and accuracy\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.16955502033233644\n",
      "Epoch [2/200], Loss: 0.11873148500919342\n",
      "Epoch [3/200], Loss: 0.07863275721669197\n",
      "Epoch [4/200], Loss: 0.051488227993249897\n",
      "Epoch [5/200], Loss: 0.039107536226511\n",
      "Epoch [6/200], Loss: 0.0356776487827301\n",
      "Epoch [7/200], Loss: 0.03436060011386871\n",
      "Epoch [8/200], Loss: 0.0334552913159132\n",
      "Epoch [9/200], Loss: 0.032321655601263044\n",
      "Epoch [10/200], Loss: 0.031614232361316684\n",
      "Epoch [11/200], Loss: 0.030620966926217078\n",
      "Epoch [12/200], Loss: 0.029832707569003105\n",
      "Epoch [13/200], Loss: 0.02877737008035183\n",
      "Epoch [14/200], Loss: 0.027532709315419197\n",
      "Epoch [15/200], Loss: 0.026804945468902587\n",
      "Epoch [16/200], Loss: 0.02587109848856926\n",
      "Epoch [17/200], Loss: 0.02503103069961071\n",
      "Epoch [18/200], Loss: 0.0241388301551342\n",
      "Epoch [19/200], Loss: 0.023387585058808325\n",
      "Epoch [20/200], Loss: 0.02236979678273201\n",
      "Epoch [21/200], Loss: 0.021804993748664857\n",
      "Epoch [22/200], Loss: 0.02126714825630188\n",
      "Epoch [23/200], Loss: 0.02040700040757656\n",
      "Epoch [24/200], Loss: 0.019933243691921235\n",
      "Epoch [25/200], Loss: 0.019320052489638327\n",
      "Epoch [26/200], Loss: 0.01884373478591442\n",
      "Epoch [27/200], Loss: 0.01804576948285103\n",
      "Epoch [28/200], Loss: 0.017869641929864885\n",
      "Epoch [29/200], Loss: 0.017412624135613442\n",
      "Epoch [30/200], Loss: 0.017103321254253387\n",
      "Epoch [31/200], Loss: 0.016586983650922774\n",
      "Epoch [32/200], Loss: 0.016625471226871014\n",
      "Epoch [33/200], Loss: 0.01625881303101778\n",
      "Epoch [34/200], Loss: 0.015961609594523907\n",
      "Epoch [35/200], Loss: 0.015787159875035286\n",
      "Epoch [36/200], Loss: 0.015500486120581627\n",
      "Epoch [37/200], Loss: 0.015340783521533013\n",
      "Epoch [38/200], Loss: 0.015107859671115876\n",
      "Epoch [39/200], Loss: 0.014886800721287728\n",
      "Epoch [40/200], Loss: 0.014774397313594818\n",
      "Epoch [41/200], Loss: 0.014602860361337662\n",
      "Epoch [42/200], Loss: 0.014655396156013013\n",
      "Epoch [43/200], Loss: 0.014559145495295524\n",
      "Epoch [44/200], Loss: 0.014325579665601253\n",
      "Epoch [45/200], Loss: 0.01407721869647503\n",
      "Epoch [46/200], Loss: 0.014121824614703656\n",
      "Epoch [47/200], Loss: 0.014078147560358047\n",
      "Epoch [48/200], Loss: 0.013942885212600231\n",
      "Epoch [49/200], Loss: 0.013581725098192691\n",
      "Epoch [50/200], Loss: 0.013522107899188996\n",
      "Epoch [51/200], Loss: 0.013563907779753208\n",
      "Epoch [52/200], Loss: 0.013492077216506004\n",
      "Epoch [53/200], Loss: 0.013492353036999702\n",
      "Epoch [54/200], Loss: 0.013590442053973674\n",
      "Epoch [55/200], Loss: 0.0133599504083395\n",
      "Epoch [56/200], Loss: 0.013273777775466442\n",
      "Epoch [57/200], Loss: 0.013238039799034595\n",
      "Epoch [58/200], Loss: 0.013172456473112106\n",
      "Epoch [59/200], Loss: 0.012832117415964604\n",
      "Epoch [60/200], Loss: 0.013079461567103863\n",
      "Epoch [61/200], Loss: 0.01274417657405138\n",
      "Epoch [62/200], Loss: 0.01286390196532011\n",
      "Epoch [63/200], Loss: 0.012907724305987358\n",
      "Epoch [64/200], Loss: 0.012681814804673196\n",
      "Epoch [65/200], Loss: 0.01273721992969513\n",
      "Epoch [66/200], Loss: 0.012702605240046978\n",
      "Epoch [67/200], Loss: 0.012695035934448241\n",
      "Epoch [68/200], Loss: 0.01275992002338171\n",
      "Epoch [69/200], Loss: 0.012627190314233303\n",
      "Epoch [70/200], Loss: 0.012489975653588772\n",
      "Epoch [71/200], Loss: 0.01262322649359703\n",
      "Epoch [72/200], Loss: 0.012520524822175503\n",
      "Epoch [73/200], Loss: 0.01232924908399582\n",
      "Epoch [74/200], Loss: 0.012244951277971268\n",
      "Epoch [75/200], Loss: 0.012284135296940803\n",
      "Epoch [76/200], Loss: 0.012165682911872864\n",
      "Epoch [77/200], Loss: 0.012128899097442627\n",
      "Epoch [78/200], Loss: 0.01201687976717949\n",
      "Epoch [79/200], Loss: 0.011929802298545837\n",
      "Epoch [80/200], Loss: 0.012190268635749816\n",
      "Epoch [81/200], Loss: 0.012339424714446068\n",
      "Epoch [82/200], Loss: 0.01210136029869318\n",
      "Epoch [83/200], Loss: 0.01205428820103407\n",
      "Epoch [84/200], Loss: 0.012179297171533108\n",
      "Epoch [85/200], Loss: 0.011892951875925064\n",
      "Epoch [86/200], Loss: 0.011984745860099793\n",
      "Epoch [87/200], Loss: 0.011814979799091817\n",
      "Epoch [88/200], Loss: 0.011646232716739178\n",
      "Epoch [89/200], Loss: 0.011809236519038677\n",
      "Epoch [90/200], Loss: 0.011829684413969517\n",
      "Epoch [91/200], Loss: 0.011942143216729165\n",
      "Epoch [92/200], Loss: 0.011671290621161462\n",
      "Epoch [93/200], Loss: 0.011956667676568031\n",
      "Epoch [94/200], Loss: 0.011636741273105145\n",
      "Epoch [95/200], Loss: 0.011780717968940735\n",
      "Epoch [96/200], Loss: 0.011687310747802257\n",
      "Epoch [97/200], Loss: 0.01162451684474945\n",
      "Epoch [98/200], Loss: 0.011612276583909988\n",
      "Epoch [99/200], Loss: 0.011512819826602936\n",
      "Epoch [100/200], Loss: 0.011562648862600326\n",
      "Epoch [101/200], Loss: 0.011389391645789147\n",
      "Epoch [102/200], Loss: 0.011595834866166116\n",
      "Epoch [103/200], Loss: 0.011425172388553619\n",
      "Epoch [104/200], Loss: 0.011586248613893986\n",
      "Epoch [105/200], Loss: 0.011632882356643677\n",
      "Epoch [106/200], Loss: 0.011393829509615898\n",
      "Epoch [107/200], Loss: 0.01137734942138195\n",
      "Epoch [108/200], Loss: 0.011371445767581463\n",
      "Epoch [109/200], Loss: 0.011231736354529858\n",
      "Epoch [110/200], Loss: 0.011316065713763236\n",
      "Epoch [111/200], Loss: 0.011416843235492706\n",
      "Epoch [112/200], Loss: 0.011286496631801129\n",
      "Epoch [113/200], Loss: 0.011247883699834347\n",
      "Epoch [114/200], Loss: 0.011309268437325954\n",
      "Epoch [115/200], Loss: 0.011261264085769654\n",
      "Epoch [116/200], Loss: 0.011102482602000236\n",
      "Epoch [117/200], Loss: 0.01119369175285101\n",
      "Epoch [118/200], Loss: 0.011081014275550843\n",
      "Epoch [119/200], Loss: 0.010949704684317113\n",
      "Epoch [120/200], Loss: 0.01116350207477808\n",
      "Epoch [121/200], Loss: 0.011125949956476689\n",
      "Epoch [122/200], Loss: 0.01110208809375763\n",
      "Epoch [123/200], Loss: 0.010907512791454792\n",
      "Epoch [124/200], Loss: 0.011017377190291881\n",
      "Epoch [125/200], Loss: 0.01086333829909563\n",
      "Epoch [126/200], Loss: 0.010974449254572392\n",
      "Epoch [127/200], Loss: 0.011004269309341907\n",
      "Epoch [128/200], Loss: 0.01118435237556696\n",
      "Epoch [129/200], Loss: 0.01094182662665844\n",
      "Epoch [130/200], Loss: 0.011004542373120785\n",
      "Epoch [131/200], Loss: 0.010964185073971748\n",
      "Epoch [132/200], Loss: 0.010714838467538356\n",
      "Epoch [133/200], Loss: 0.01086038202047348\n",
      "Epoch [134/200], Loss: 0.010996812842786313\n",
      "Epoch [135/200], Loss: 0.01078329909592867\n",
      "Epoch [136/200], Loss: 0.010860888995230198\n",
      "Epoch [137/200], Loss: 0.010610800459980965\n",
      "Epoch [138/200], Loss: 0.010730912014842033\n",
      "Epoch [139/200], Loss: 0.01074572216719389\n",
      "Epoch [140/200], Loss: 0.010893089585006238\n",
      "Epoch [141/200], Loss: 0.010760993510484696\n",
      "Epoch [142/200], Loss: 0.010835372880101203\n",
      "Epoch [143/200], Loss: 0.010681568309664727\n",
      "Epoch [144/200], Loss: 0.010699800737202168\n",
      "Epoch [145/200], Loss: 0.010771716274321079\n",
      "Epoch [146/200], Loss: 0.010647982731461525\n",
      "Epoch [147/200], Loss: 0.010652079991996289\n",
      "Epoch [148/200], Loss: 0.010488872341811657\n",
      "Epoch [149/200], Loss: 0.010584134757518768\n",
      "Epoch [150/200], Loss: 0.010728105306625366\n",
      "Epoch [151/200], Loss: 0.01048425205051899\n",
      "Epoch [152/200], Loss: 0.01066602934151888\n",
      "Epoch [153/200], Loss: 0.010616563856601716\n",
      "Epoch [154/200], Loss: 0.01058115430176258\n",
      "Epoch [155/200], Loss: 0.010465907081961632\n",
      "Epoch [156/200], Loss: 0.010574497431516647\n",
      "Epoch [157/200], Loss: 0.010554357282817364\n",
      "Epoch [158/200], Loss: 0.010579902343451977\n",
      "Epoch [159/200], Loss: 0.010542485602200032\n",
      "Epoch [160/200], Loss: 0.010406412109732628\n",
      "Epoch [161/200], Loss: 0.010538547672331334\n",
      "Epoch [162/200], Loss: 0.010527565740048886\n",
      "Epoch [163/200], Loss: 0.010493735857307911\n",
      "Epoch [164/200], Loss: 0.010408181957900524\n",
      "Epoch [165/200], Loss: 0.010576396733522415\n",
      "Epoch [166/200], Loss: 0.010554083585739137\n",
      "Epoch [167/200], Loss: 0.010435541421175002\n",
      "Epoch [168/200], Loss: 0.010490129441022874\n",
      "Epoch [169/200], Loss: 0.010399758517742157\n",
      "Epoch [170/200], Loss: 0.010388223454356194\n",
      "Epoch [171/200], Loss: 0.01044565074145794\n",
      "Epoch [172/200], Loss: 0.010448749363422393\n",
      "Epoch [173/200], Loss: 0.010509836338460445\n",
      "Epoch [174/200], Loss: 0.010485754199326038\n",
      "Epoch [175/200], Loss: 0.010215334556996823\n",
      "Epoch [176/200], Loss: 0.010338410213589668\n",
      "Epoch [177/200], Loss: 0.010363621227443219\n",
      "Epoch [178/200], Loss: 0.010469961948692798\n",
      "Epoch [179/200], Loss: 0.010409031547605991\n",
      "Epoch [180/200], Loss: 0.01018025640398264\n",
      "Epoch [181/200], Loss: 0.010246441029012203\n",
      "Epoch [182/200], Loss: 0.01030556857585907\n",
      "Epoch [183/200], Loss: 0.010336973629891872\n",
      "Epoch [184/200], Loss: 0.010216662287712097\n",
      "Epoch [185/200], Loss: 0.010284334868192673\n",
      "Epoch [186/200], Loss: 0.010398312695324421\n",
      "Epoch [187/200], Loss: 0.010206919759511948\n",
      "Epoch [188/200], Loss: 0.010255079865455628\n",
      "Epoch [189/200], Loss: 0.010355791859328747\n",
      "Epoch [190/200], Loss: 0.01028495967388153\n",
      "Epoch [191/200], Loss: 0.01016972579061985\n",
      "Epoch [192/200], Loss: 0.010179894976317883\n",
      "Epoch [193/200], Loss: 0.010144797898828984\n",
      "Epoch [194/200], Loss: 0.010119970850646497\n",
      "Epoch [195/200], Loss: 0.010176470801234246\n",
      "Epoch [196/200], Loss: 0.010205992497503757\n",
      "Epoch [197/200], Loss: 0.010224816538393498\n",
      "Epoch [198/200], Loss: 0.010040298774838448\n",
      "Epoch [199/200], Loss: 0.010122183188796043\n",
      "Epoch [200/200], Loss: 0.010211713649332523\n"
     ]
    }
   ],
   "source": [
    "# Training loop with batch processing\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0  # Reset running loss for each epoch\n",
    "    \n",
    "    # Process each batch\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(batch_x).squeeze()  # Remove singleton dimension\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()# Accumulate batch loss\n",
    "\n",
    "    # Calculate the average loss for the epoch\n",
    "    epoch_loss = (running_loss / len(train_loader))\n",
    "    \n",
    "    # Calculate accuracy and loss for validation set\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        y_val_pred = model(X_val_tensor).squeeze()\n",
    "        val_loss = criterion(y_val_pred, y_val_tensor).item()\n",
    "        val_mse = mean_squared_error(y_val_np, y_val_pred.numpy())\n",
    "        val_r2 = r2_score(y_val_np, y_val_pred.numpy())  # R² score\n",
    "        val_accuracy = val_r2 * 100  # Convert to percentage\n",
    "\n",
    "        # Store logs for this epoch\n",
    "        train_losses.append(epoch_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(val_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Print results for each epoch\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model and logs\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'val_losses': val_losses,\n",
    "    'val_accuracies': val_accuracies\n",
    "}, 'cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test data: 0.0053165791610501585\n",
      "R² score (Accuracy) on test data: 0.8644319494102973\n",
      "Accuracy: 86.44319494102973%\n",
      "Mean Absolute Error (MAE) on test data: 0.06011723784290252\n",
      "Root Mean Squared Error (RMSE) on test data: 0.07291487612997884\n",
      "Mean Absolute Percentage Error (MAPE) on test data: 81.37127959813154%\n"
     ]
    }
   ],
   "source": [
    "# Reshape the test data to match the CNN input format\n",
    "X_test_reduced = X_test_reduced.reshape((X_test_reduced.shape[0], 1, 1, n_components))\n",
    "\n",
    "# Convert the reshaped data to tensor\n",
    "X_test_tensor = torch.tensor(X_test_reduced, dtype=torch.float32)\n",
    "\n",
    "# Proceed with the test\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).flatten().numpy()\n",
    "\n",
    "    # Calculate MSE, MAE, RMSE, R² score, and MAPE\n",
    "    test_mse = mean_squared_error(y_test.values, y_test_pred)\n",
    "    test_r2 = r2_score(y_test.values, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test.values, y_test_pred)\n",
    "    test_rmse = mean_squared_error(y_test.values, y_test_pred, squared=False)\n",
    "    test_mape = np.mean(np.abs((y_test.values - y_test_pred) / y_test.values)) * 100\n",
    "\n",
    "    # Calculate accuracy as R² score in percentage\n",
    "    test_accuracy = test_r2 * 100\n",
    "\n",
    "    print(f'Mean Squared Error on test data: {test_mse}')\n",
    "    print(f'R² score (Accuracy) on test data: {test_r2}')\n",
    "    print(f'Accuracy: {test_accuracy}%')\n",
    "    print(f'Mean Absolute Error (MAE) on test data: {test_mae}')\n",
    "    print(f'Root Mean Squared Error (RMSE) on test data: {test_rmse}')\n",
    "    print(f'Mean Absolute Percentage Error (MAPE) on test data: {test_mape}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
